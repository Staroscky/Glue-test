# ğŸ“Š Glue Job - ExtraÃ§Ã£o de IDs por Matching de CPF

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Responsabilidades](#responsabilidades)
- [Arquitetura](#arquitetura)
- [Conceitos Principais](#conceitos-principais)
- [Fluxo de ExecuÃ§Ã£o](#fluxo-de-execuÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
- [ManutenÃ§Ã£o](#manutenÃ§Ã£o)

---

## ğŸ¯ VisÃ£o Geral

Este job AWS Glue realiza a **extraÃ§Ã£o diÃ¡ria de IDs** da Tabela B com base em matching de CPF com a Tabela A, gerando um arquivo comprimido `.txt.gz` no S3 para consumo por serviÃ§os downstream.

### **Contexto de NegÃ³cio**

O job Ã© parte crÃ­tica do pipeline de dados, alimentando serviÃ§os essenciais que dependem de uma lista atualizada diariamente de IDs elegÃ­veis. A integridade e disponibilidade deste arquivo impactam diretamente operaÃ§Ãµes de negÃ³cio.

### **CaracterÃ­sticas Principais**

- âœ… **Resultado controlado**: SaÃ­da limitada a ~100k IDs (tamanho da Tabela A)
- âœ… **ValidaÃ§Ã£o rigorosa**: MÃºltiplas camadas de validaÃ§Ã£o de integridade
- âœ… **Sobrescrita atÃ´mica**: Garante que o arquivo active nunca fique corrompido
- âœ… **Rastreabilidade**: Metadados completos e logs detalhados

---

## ğŸ­ Responsabilidades

### **O que o Job FAZ:**

1. **Identificar partiÃ§Ã£o mais recente** da Tabela B via Glue Catalog
2. **Ler apenas a partiÃ§Ã£o necessÃ¡ria** usando push-down predicate
3. **Realizar JOIN otimizado** entre Tabela A (100k) e Tabela B (300M)
4. **Extrair IDs Ãºnicos** que fazem match entre as tabelas
5. **Gerar arquivo comprimido** `.txt.gz` com um ID por linha
6. **Validar integridade** atravÃ©s de checksums MD5 e contagens
7. **Mover atomicamente** para pasta active sobrescrevendo versÃ£o anterior
8. **Registrar metadados** (quantidade, checksum, partiÃ§Ã£o origem, timestamp)

### **O que o Job NÃƒO FAZ:**

- âŒ NÃ£o processa todas as partiÃ§Ãµes da Tabela B (apenas a Ãºltima)
- âŒ NÃ£o faz transformaÃ§Ãµes nos dados (apenas extraÃ§Ã£o)
- âŒ NÃ£o mantÃ©m histÃ³rico de versÃµes (sobrescreve latest.txt.gz)
- âŒ NÃ£o notifica falhas automaticamente (requer CloudWatch Alarms)
- âŒ NÃ£o valida qualidade dos dados de origem

---

## ğŸ—ï¸ Arquitetura

### **Diagrama de Fluxo**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AWS GLUE JOB                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. IDENTIFICAR PARTIÃ‡ÃƒO                                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚     â”‚  Glue Catalog    â”‚ â† get_partitions()                     â”‚
â”‚     â”‚  (Metadados)     â”‚ â†’ Ãºltima partiÃ§Ã£o: 20251022            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                                                                 â”‚
â”‚  2. LEITURA OTIMIZADA                                           â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚     â”‚   Tabela A       â”‚     â”‚   Tabela B       â”‚              â”‚
â”‚     â”‚   100k registros â”‚     â”‚   300M registros â”‚              â”‚
â”‚     â”‚   S3/Parquet     â”‚     â”‚   S3/Parquet     â”‚              â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚              â”‚                        â”‚                         â”‚
â”‚              â”‚ push-down predicate    â”‚                         â”‚
â”‚              â”‚ (ano_mes_dia=Ãºltima)   â”‚                         â”‚
â”‚              â†“                        â†“                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚     â”‚      BROADCAST HASH JOIN           â”‚                     â”‚
â”‚     â”‚  b.documento = CONCAT('000',       â”‚                     â”‚
â”‚     â”‚                a.documento)        â”‚                     â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                      â†“                                          â”‚
â”‚              ~100k IDs Ãºnicos                                   â”‚
â”‚                                                                 â”‚
â”‚  3. GERAÃ‡ÃƒO DE ARQUIVO                                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚     â”‚  stage/          â”‚                                        â”‚
â”‚     â”‚  stage_*.txt.gz  â”‚ â† Arquivo temporÃ¡rio                   â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚              â”‚                                                  â”‚
â”‚              â”‚ ValidaÃ§Ãµes:                                      â”‚
â”‚              â”‚ â€¢ IDs vazios                                     â”‚
â”‚              â”‚ â€¢ MD5 checksum                                   â”‚
â”‚              â”‚ â€¢ Contagem                                       â”‚
â”‚              â”‚ â€¢ Tamanho > 0                                    â”‚
â”‚              â†“                                                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚     â”‚  active/         â”‚                                        â”‚
â”‚     â”‚  latest.txt.gz   â”‚ â† Sobrescrita atÃ´mica                  â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Estrutura S3**

```
s3://seu-bucket/
â”œâ”€â”€ stage/
â”‚   â”œâ”€â”€ stage_20251022_120000.txt.gz  â† Arquivos temporÃ¡rios (mantidos para auditoria)
â”‚   â”œâ”€â”€ stage_20251021_120000.txt.gz
â”‚   â””â”€â”€ ...
â””â”€â”€ active/
    â””â”€â”€ latest.txt.gz  â† Arquivo consumido por serviÃ§os (sempre atualizado)
```

---

## ğŸ’¡ Conceitos Principais

### **1. Push-Down Predicate**

**O que Ã©:** TÃ©cnica de otimizaÃ§Ã£o que aplica filtros diretamente na leitura dos dados, antes de carregar na memÃ³ria.

**Por que usar:**
```python
# âŒ SEM push-down: LÃª 300M registros â†’ filtra
df_b = glueContext.create_dynamic_frame.from_catalog(...)
df_b_filtrado = df_b.filter(col("ano_mes_dia") == "20251022")  # Tarde demais!

# âœ… COM push-down: LÃª apenas a partiÃ§Ã£o necessÃ¡ria
df_b = glueContext.create_dynamic_frame.from_catalog(
    push_down_predicate="ano_mes_dia='20251022'"  # Filtro aplicado na leitura!
)
```

**BenefÃ­cio:** Economia de 99% no I/O se houver 100 partiÃ§Ãµes diÃ¡rias.

---

### **2. Broadcast Join**

**O que Ã©:** EstratÃ©gia de JOIN onde a tabela menor Ã© copiada inteira para cada worker, evitando shuffle de rede.

**Como funciona:**

```
JOIN NORMAL (Shuffle):                 BROADCAST JOIN:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Worker1 â”‚  â”‚ Worker2 â”‚              â”‚  Tabela A (100k) â”‚
â”‚ A + B   â”‚  â”‚ A + B   â”‚              â”‚   [BROADCAST]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†•            â†•                      â†“    â†“    â†“    â†“
  SHUFFLE      SHUFFLE               â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”
  (LENTO)      (LENTO)               â”‚ W1â”‚â”‚ W2â”‚â”‚ W3â”‚â”‚ W4â”‚
                                     â”‚ B â”‚â”‚ B â”‚â”‚ B â”‚â”‚ B â”‚
                                     â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜
                                     (RÃPIDO - sem shuffle)
```

**Quando usar:**
- Tabela pequena < 100 MB
- RelaÃ§Ã£o de tamanho > 100:1

**No nosso caso:**
- Tabela A: ~1 MB (100k registros)
- Tabela B: ~100 GB (300M registros)
- **Perfeito para broadcast!**

```python
resultado = df_b.join(
    broadcast(df_a),  # â† Force broadcast da tabela menor
    df_b["documento"] == df_a["documento_formatado"],
    "inner"
)
```

---

### **3. MD5 Checksum**

**O que Ã©:** FunÃ§Ã£o hash criptogrÃ¡fica que gera uma "impressÃ£o digital" de 32 caracteres para qualquer conteÃºdo.

**Propriedades:**
- Qualquer mudanÃ§a (atÃ© 1 bit) â†’ MD5 completamente diferente
- Mesmo conteÃºdo â†’ Sempre o mesmo MD5
- ImpossÃ­vel recriar o conteÃºdo original a partir do MD5

**Uso no Job:**
```python
# Calcular antes de enviar
conteudo = "ID001\nID002\nID003"
md5_original = hashlib.md5(conteudo.encode('utf-8')).hexdigest()
# â†’ 'f3d5c8a...' (32 caracteres hex)

# Baixar do S3 e recalcular
conteudo_s3 = baixar_do_s3()
md5_s3 = hashlib.md5(conteudo_s3.encode('utf-8')).hexdigest()

# Validar integridade
if md5_original == md5_s3:
    print("âœ… Arquivo Ã­ntegro!")
else:
    raise Exception("âŒ Arquivo corrompido!")
```

**Por que Ã© importante:** Garante que o arquivo nÃ£o foi corrompido durante upload/download ou armazenamento no S3.

---

### **4. Sobrescrita AtÃ´mica no S3**

**O que Ã©:** TÃ©cnica que garante que o arquivo destino nunca fique em estado inconsistente durante atualizaÃ§Ã£o.

**Problema sem atomicidade:**
```
1. ServiÃ§o lÃª latest.txt.gz  âœ… VersÃ£o antiga (vÃ¡lida)
2. Job comeÃ§a a escrever...  âš ï¸  Arquivo corrompido (50% escrito)
3. ServiÃ§o lÃª latest.txt.gz  âŒ ERRO! Arquivo corrompido
```

**SoluÃ§Ã£o com staging:**
```python
# 1. Escrever em arquivo temporÃ¡rio (stage)
upload("stage/stage_20251022.txt.gz")

# 2. Validar integridade
validar_md5()
validar_contagem()

# 3. Copiar atomicamente (operaÃ§Ã£o atÃ´mica do S3)
s3_client.copy_object(
    CopySource="stage/stage_20251022.txt.gz",
    Key="active/latest.txt.gz"  # â† S3 garante atomicidade
)
```

**Resultado:** ServiÃ§os sempre veem arquivo vÃ¡lido (versÃ£o antiga OU nova completa, nunca parcial).

---

### **5. Distinct (DeduplicaÃ§Ã£o)**

**O que Ã©:** Remove registros duplicados do resultado.

**Por que usar:**
```python
# CenÃ¡rio: Mesmo CPF pode aparecer mÃºltiplas vezes em B
Tabela A: CPF = 12345678901
Tabela B: 
  - ID001, CPF = 00012345678901 (transaÃ§Ã£o 1)
  - ID002, CPF = 00012345678901 (transaÃ§Ã£o 2)
  - ID003, CPF = 00012345678901 (transaÃ§Ã£o 3)

# Sem distinct: Retorna IDs repetidos
resultado = ["ID001", "ID001", "ID001"]

# Com distinct: Retorna IDs Ãºnicos
resultado.distinct() â†’ ["ID001"]
```

**ImplementaÃ§Ã£o:**
```python
resultado = df_b.join(...).select(col("id")).distinct()
```

---

## ğŸ”„ Fluxo de ExecuÃ§Ã£o

### **Passo a Passo Detalhado**

#### **FASE 1: InicializaÃ§Ã£o (30s)**
```
1. Spark inicializa cluster
2. Glue Context Ã© criado
3. ConexÃµes S3 e Glue Catalog estabelecidas
```

#### **FASE 2: IdentificaÃ§Ã£o de PartiÃ§Ã£o (5s)**
```
1. Consulta Glue Catalog via API (get_partitions)
2. Lista todas as partiÃ§Ãµes da Tabela B
3. Identifica a maior (Ãºltima): ano_mes_dia = MAX(partiÃ§Ãµes)
4. Log: "Ãšltima partiÃ§Ã£o: 20251022"
```

#### **FASE 3: Leitura de Dados (2-3 min)**
```
â”Œâ”€ Tabela A (rÃ¡pido: 100k registros)
â”‚  1. Leitura do S3
â”‚  2. Parse Parquet â†’ DataFrame Spark
â”‚  3. Adiciona coluna: documento_formatado = CONCAT('000', documento)
â”‚  
â””â”€ Tabela B (otimizado: push-down predicate)
   1. Leitura APENAS da partiÃ§Ã£o 20251022
   2. Spark divide leitura entre workers
   3. Parse Parquet â†’ DataFrame Spark
   
Total lido: ~1 GB (partiÃ§Ã£o Ãºnica) ao invÃ©s de ~100 GB (todas partiÃ§Ãµes)
```

#### **FASE 4: Processamento - JOIN (3-5 min)**
```
1. Broadcast da Tabela A para todos os workers
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Tabela A   â”‚ â†’ Copiada para todos os workers
   â”‚ (1 MB)     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
2. Join distribuÃ­do
   Worker 1: Processa 75M registros de B + cÃ³pia de A
   Worker 2: Processa 75M registros de B + cÃ³pia de A
   Worker 3: Processa 75M registros de B + cÃ³pia de A
   Worker 4: Processa 75M registros de B + cÃ³pia de A
   
3. Filtra apenas matches
   300M registros â†’ ~100k matches
   
4. Remove duplicatas (.distinct())
   ~100k â†’ ~100k Ãºnicos
```

#### **FASE 5: Coleta e ValidaÃ§Ã£o (30s)**
```
1. Collect IDs para driver
   100k strings Ã— 10 chars = ~1 MB (cabe na memÃ³ria)
   
2. ValidaÃ§Ã£o 1: IDs vazios
   âœ“ Nenhum ID vazio encontrado
   
3. CriaÃ§Ã£o do conteÃºdo
   conteudo = "ID001\nID002\n...\nID100000"
   
4. CÃ¡lculo MD5
   md5_original = hashlib.md5(conteudo)
```

#### **FASE 6: CompressÃ£o e Upload (1 min)**
```
1. CompressÃ£o GZIP
   1 MB (texto) â†’ ~400 KB (comprimido ~60%)
   
2. Upload para stage/
   s3://bucket/stage/stage_20251022_120000.txt.gz
   
3. ValidaÃ§Ã£o de upload
   - Baixa arquivo
   - Recalcula MD5
   - Compara: md5_original == md5_s3 âœ“
   - Conta linhas: 100k == 100k âœ“
   - Verifica tamanho: 400 KB > 0 âœ“
```

#### **FASE 7: MovimentaÃ§Ã£o AtÃ´mica (10s)**
```
1. S3 Copy (operaÃ§Ã£o atÃ´mica)
   stage/stage_20251022_120000.txt.gz 
   â†’ active/latest.txt.gz
   
2. Metadados adicionados
   total_ids: "100000"
   md5_checksum: "f3d5c8a..."
   created_at: "20251022_120000"
   source_partition: "20251022"
   
3. ValidaÃ§Ã£o final
   Tamanho active == Tamanho stage âœ“
```

#### **FASE 8: FinalizaÃ§Ã£o (5s)**
```
1. Log de resumo
2. MÃ©tricas CloudWatch
3. Job commit
4. Spark shutdown
```

### **Tempo Total Estimado: 8-12 minutos**

---

## âš™ï¸ ConfiguraÃ§Ã£o

### **IAM Role - PermissÃµes NecessÃ¡rias**

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:DeleteObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::seu-bucket/*",
        "arn:aws:s3:::seu-bucket"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "glue:GetDatabase",
        "glue:GetTable",
        "glue:GetPartitions"
      ],
      "Resource": [
        "arn:aws:glue:*:*:catalog",
        "arn:aws:glue:*:*:database/seu_database",
        "arn:aws:glue:*:*:table/seu_database/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "arn:aws:logs:*:*:/aws-glue/*"
    }
  ]
}
```

## ğŸ“š ReferÃªncias

- [AWS Glue Documentation](https://docs.aws.amazon.com/glue/)
- [PySpark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)
- [S3 Best Practices](https://docs.aws.amazon.com/AmazonS3/latest/userguide/optimizing-performance.html)
- [Glue Job Parameters](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html)